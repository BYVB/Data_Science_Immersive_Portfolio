{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting movie reviews: Using Natural Language Processing to build out a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: to collect review text from good and bad movies in the past and see if it can be used to create an effective classifier using ensemble methods. Use 2016 movie reviews as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imdbpie import Imdb\n",
    "imdb = Imdb(anonymize=True) # to proxy requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame and prep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## calling the top 250 with this handy IMDBpie method top_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>can_rate</th>\n",
       "      <th>image</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>tconst</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>{u'url': u'https://images-na.ssl-images-amazon...</td>\n",
       "      <td>1715732</td>\n",
       "      <td>9.3</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>feature</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>{u'url': u'https://images-na.ssl-images-amazon...</td>\n",
       "      <td>1172712</td>\n",
       "      <td>9.2</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>feature</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  can_rate                                              image  num_votes  \\\n",
       "0     True  {u'url': u'https://images-na.ssl-images-amazon...    1715732   \n",
       "1     True  {u'url': u'https://images-na.ssl-images-amazon...    1172712   \n",
       "\n",
       "   rating     tconst                     title     type  year  \n",
       "0     9.3  tt0111161  The Shawshank Redemption  feature  1994  \n",
       "1     9.2  tt0068646             The Godfather  feature  1972  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = imdb.top_250()\n",
    "df = pd.DataFrame(top)\n",
    "tTitle_list = [i.encode(\"ascii\") for i in df[\"tconst\"]]\n",
    "tTitle_list \n",
    "df['year'] = [i.encode(\"ascii\") for i in df['year']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Next scraping the bottom 100 from IMDB itself with xpath and cleansing the results with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"http://www.imdb.com/chart/bottom\").text\n",
    "aa = Selector(text=r).xpath(\"//*[contains(@class, 'titleColumn')]//@href\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "btitle_list = []\n",
    "for i in aa:   \n",
    "    test = re.search('(?<=title/)\\w+', i )\n",
    "    btitle_list.append(test.group(0).encode('ascii'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(btitle_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reviews_bottom = []\n",
    "# for i in btitle_list:\n",
    "#     rev =imdb.get_title_reviews(i, max_results=5)\n",
    "#     reviews_bottom.append(rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##here's a function to make this imdb fetch a bit less painful\n",
    "def get_imdb(titles_list, num_reviews):\n",
    "    output = []\n",
    "    for i in titles_list:\n",
    "        rev =imdb.get_title_reviews(i, max_results=num_reviews)\n",
    "        output.append(rev)\n",
    "    return output\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_imdb_rating(titles_list):\n",
    "    output = []\n",
    "    for i in titles_list:\n",
    "        output.append(imdb.get_title_by_id(i).rating)\n",
    "    return output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reviews_top = get_imdb(tTitle_list,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reviews_bottom = get_imdb(btitle_list,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt4458206', 'tt4009460', 'tt0270846']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##these lists of titles are also in the same format:\n",
    "print tTitle_list[:3]\n",
    "print btitle_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##cool, so now these are both in the same format: lists of lists of data objects \n",
    "\n",
    "reviews_top\n",
    "reviews_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are commented out below so i don't run them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles_and_ranks = zip(btitle_list,bottom_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[['tconst','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_bot = pd.DataFrame(titles_and_ranks, columns =('tconst','rating') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndf = pd.concat([df,df_bot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0068646</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0071562</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0050083</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  rating\n",
       "0  tt0111161     9.3\n",
       "1  tt0068646     9.2\n",
       "2  tt0071562     9.0\n",
       "3  tt0468569     9.0\n",
       "4  tt0050083     8.9"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>rating</th>\n",
       "      <th>all_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>9.3</td>\n",
       "      <td>[&lt;Review: Why do I want to wri&gt;, &lt;Review: \\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0068646</td>\n",
       "      <td>9.2</td>\n",
       "      <td>[&lt;Review: Rather than concentr&gt;, &lt;Review: \\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0071562</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[&lt;Review: \\nThis movie is way t&gt;, &lt;Review: \\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[&lt;Review: We've been subjected&gt;, &lt;Review: Chri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0050083</td>\n",
       "      <td>8.9</td>\n",
       "      <td>[&lt;Review: \\nAn excellent courtr&gt;, &lt;Review: \\nT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  rating                                        all_reviews\n",
       "0  tt0111161     9.3  [<Review: Why do I want to wri>, <Review: \\nCa...\n",
       "1  tt0068646     9.2  [<Review: Rather than concentr>, <Review: \\nTh...\n",
       "2  tt0071562     9.0  [<Review: \\nThis movie is way t>, <Review: \\nT...\n",
       "3  tt0468569     9.0  [<Review: We've been subjected>, <Review: Chri...\n",
       "4  tt0050083     8.9  [<Review: \\nAn excellent courtr>, <Review: \\nT..."
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf['all_reviews'] = reviews_top + reviews_bottom\n",
    "ndf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's get this data into a format that vectorizer is down with...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unravel(col):\n",
    "    review_str = ''\n",
    "    for a in col:\n",
    "        review_str+= a.text\n",
    "        return review_str\n",
    "ndf['flat_reviews'] = ndf['all_reviews'].apply(unravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Why', u'do', u'I', u'want', u'to', u'write', u'the', u'234th', u'comment', u'on', u'The', u'Shawshank', u'Redemption?', u'I', u'am', u'not', u'sure', u'-', u'almost', u'everything', u'that', u'could', u'be', u'possibly', u'said', u'about', u'it', u'has', u'been', u'said.', u'But', u'like', u'so', u'many', u'other', u'people', u'who', u'wrote', u'comments,', u'I', u'was', u'and', u'am', u'profoundly', u'moved', u'by', u'this', u'simple', u'and', u'eloquent', u'depiction', u'of', u'hope', u'and', u'friendship', u'and', u'redemption.', u'The', u'only', u'other', u'movie', u'I', u'have', u'ever', u'seen', u'that', u'effects', u'me', u'as', u'strongly', u'is', u'To', u'Kill', u'a', u'Mockingbird.', u'Both', u'movies', u'leave', u'me', u'feeling', u'cleaner', u'for', u'having', u'watched', u'them.', u'I', u\"didn't\", u'intend', u'to', u'see', u'this', u'movie', u'at', u'all:', u'I', u'do', u'not', u'like', u'prison', u'movies', u'and', u'I', u\"don't\", u'normally', u'watch', u'them.', u'I', u'work', u'at', u'a', u'branch', u'library', u'and', u'one', u'day', u'as', u'I', u'was', u'checking', u'The', u'Shawshank', u'Redemption', u'out', u'to', u'one', u'of', u'our', u'older', u'patrons,', u'she', u'said', u'to', u'me,', u'\"Whenever', u'I', u'feel', u'down', u'or', u'depressed,', u'I', u'check', u'out', u'this', u'movie', u'and', u'watch', u'it', u'and', u'it', u'always', u'makes', u'me', u'feel', u'better.\"', u'At', u'the', u'time,', u'I', u'thought', u'that', u'was', u'very', u'strange.', u'One', u'day', u'there', u'was', u'nothing', u'on', u'TV', u'except', u'things', u'I', u'absolutely', u'would', u'not', u'watch', u'under', u'any', u'circumstance', u'or', u'things', u'that', u'I', u'had', u'seen', u'too', u'many', u'times', u'already.', u'I', u'remembered', u'what', u'she', u'said,', u'so', u'I', u'watched', u'it.', u'I', u'have', u'watched', u'it', u'many', u'many', u'times', u'since', u'then', u'and', u'it', u'gets', u'better', u'with', u'every', u'showing.', u'No', u'action,', u'no', u'special', u'effects', u'-', u'just', u'men', u'in', u'prison', u'uniforms', u'talking', u'to', u'each', u'other.', u'The', u'Shawshank', u'Redemption', u'and', u'To', u'Kill', u'a', u'Mockingbird', u'are', u'the', u'best', u'movies', u'I', u'have', u'ever', u'seen.', u'I', u'do', u'not', u'judge', u'it', u'by', u\"it's\", u'technical', u'merits', u'-', u'I', u\"don't\", u'really', u'care', u'about', u'that.', u'I', u'have', u'read', u'that', u'Citizen', u'Kane', u'or', u'The', u'Godfather', u'or', u'this', u'or', u'that', u'movie', u'is', u'the', u'best', u'movie', u'ever', u'made.', u'They', u'may', u'have', u'the', u'best', u'technique', u'or', u'be', u'the', u'most', u'influential', u'motion', u'pictures', u'ever', u'made,', u'but', u'not', u'the', u'best.', u'The', u'best', u'movies', u'are', u'ones', u'that', u'touch', u'the', u'soul.', u'It', u'takes', u'a', u'movie', u'like', u'The', u'Shawshank', u'Redemption', u'to', u'touch', u'the', u'soul.']\n"
     ]
    }
   ],
   "source": [
    "for i in ndf['flat_reviews'][:1]:\n",
    "    print i.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...and stem the base words before we vectorize here's a function to run the porter stemmer on a list containing one string, which our df  column now is let's ascii these up while we're at it to get rid of weird nonsense words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a list of a string of word'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def make_stem(line):\n",
    "    return_stemmed = ''\n",
    "    for i in line.split():\n",
    "        stemmer = PorterStemmer()\n",
    "        try :\n",
    "            i.encode(\"ascii\")\n",
    "            return_stemmed += ' '+ stemmer.stem(i).encode('ascii')\n",
    "        except UnicodeDecodeError: \n",
    "            return_stemmed += ''\n",
    "        except UnicodeEncodeError:\n",
    "            return_stemmed += ''\n",
    "    return return_stemmed\n",
    "\n",
    "\n",
    "\n",
    "tester = \"a listing u'\\xe9' of a strings of words\"\n",
    "make_stem(tester)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Whi do I want to write the 234th comment on T...\n",
       "1     Rather than concentr on everyth that is great...\n",
       "Name: flat_reviews, dtype: object"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## go ahead and replace flat reviews with stemmed version of self\n",
    "\n",
    "ndf['flat_reviews'] = ndf['flat_reviews'].apply(make_stem)\n",
    "ndf['flat_reviews'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ndf['flat_reviews']\n",
    "y = ndf['rating'].apply(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_ndf = ndf[['tconst', 'rating','flat_reviews' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_ndf.to_csv(\"Checkpoint_model_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aight let's make a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##from there, vectorize these words to translate them into useable features with mathematical values on \n",
    "## which to regress, here I'm also casting an \"all X feats\" variable for cross validation, I'll later fit a new one\n",
    "## for just X_train\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "make_featuresCV = TfidfVectorizer(stop_words='english', strip_accents = 'ascii')\n",
    "make_featuresCV.fit(X)\n",
    "all_X_feats = make_featuresCV.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## let's start by splitting this up\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##now i'll refit my make_features instance of tfid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "make_features = TfidfVectorizer(stop_words='english', strip_accents = 'ascii')\n",
    "make_features.fit(X_train)\n",
    "X_train_features = make_features.transform(X_train)\n",
    "X_test_features = make_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##looks good\n",
    "X_train_features.todense()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calibrate expectations, let's run a super simple decision tree with some cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier 5xCV score mean  0.720207806768\n"
     ]
    }
   ],
   "source": [
    "TreeClf = DecisionTreeClassifier()\n",
    "s = cross_val_score(TreeClf, all_X_feats, y, cv = 5).mean()\n",
    "print \"Decision Tree Classifier 5xCV score mean \", s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREEE ACCURACY SCORE 0.671428571429\n"
     ]
    }
   ],
   "source": [
    "TreeClf_a = DecisionTreeClassifier()\n",
    "TreeClf_a.fit(X_train_features.todense(), y_train)\n",
    "\n",
    "ypred_tclf = TreeClf_a.predict(X_test_features)\n",
    "print \"DECISION TREEE ACCURACY SCORE\", accuracy_score(y_test, ypred_tclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, this is a pretty low score. Let's fit out some other models and compare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of estimators 5 5xCV Score:  0.737610789402\n",
      "num of estimators 10 5xCV Score:  0.745820724955\n",
      "num of estimators 20 5xCV Score:  0.765462885571\n",
      "num of estimators 30 5xCV Score:  0.759278932538\n",
      "num of estimators 40 5xCV Score:  0.754520030764\n",
      "num of estimators 50 5xCV Score:  0.760434549043\n",
      "num of estimators 60 5xCV Score:  0.76293141676\n",
      "num of estimators 70 5xCV Score:  0.760510558005\n",
      "num of estimators 80 5xCV Score:  0.765712550655\n"
     ]
    }
   ],
   "source": [
    "##This is a decision tree with bagging, tested across a number of differenct tree schemas\n",
    "\n",
    "for n_est in [5, 10,20,30,40,50,60,70, 80]:\n",
    "    BAgg_clf = BaggingClassifier(base_estimator = DTree_clf, n_estimators = n_est)\n",
    "    print \"num of estimators\", n_est, \"5xCV Score: \", cross_val_score(BAgg_clf, all_X_feats, y, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirty looks pretty good, let's test accuracy with 20 trees compared to our test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGED TREE ACCURACY SCORE 0.785714285714\n"
     ]
    }
   ],
   "source": [
    "BAgg_clf_30 = BaggingClassifier(base_estimator = DTree_clf, n_estimators = 20)\n",
    "BAgg_clf_30.fit(X_train_features, y_train)\n",
    "y_pred_bclf3 = BAgg_clf_30.predict(X_test_features)\n",
    "print \"BAGGED TREE ACCURACY SCORE\", accuracy_score(y_test, y_pred_bclf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, that seems pretty good...too good to be true? Here's a slightly more sophisticated model with bootstrapped features to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimators:  5 5x CV score:  0.754401396056\n",
      "number of estimators:  10 5x CV score:  0.757385198272\n",
      "number of estimators:  20 5x CV score:  0.751897721566\n",
      "number of estimators:  30 5x CV score:  0.748761901425\n",
      "number of estimators:  40 5x CV score:  0.748729736087\n",
      "number of estimators:  50 5x CV score:  0.760191690732\n",
      "number of estimators:  60 5x CV score:  0.757375955743\n",
      "number of estimators:  70 5x CV score:  0.759956857073\n",
      "number of estimators:  80 5x CV score:  0.754594821848\n"
     ]
    }
   ],
   "source": [
    "for n_est in [5,10,20,30,40,50,60,70,80]:\n",
    "    BAgg_clf = BaggingClassifier(base_estimator=DTree_clf, \n",
    "                                 n_estimators=n_est, \n",
    "                                bootstrap_features=True)\n",
    "    print 'number of estimators: ',n_est, '5x CV score: ', cross_val_score(BAgg_clf,all_X_feats ,y\n",
    "                                                                           , cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGED TREE W/ FEAT BAGGING ACCURACY SCORE 0.814285714286\n"
     ]
    }
   ],
   "source": [
    "BAgg_clf_50 = BaggingClassifier(base_estimator=DTree_clf,  n_estimators=50, bootstrap_features=True)\n",
    "BAgg_clf_50.fit(X_train_features, y_train) \n",
    "y_pred_bclf5 = BAgg_clf_50.predict(X_test_features)\n",
    "print \"BAGGED TREE W/ FEAT BAGGING ACCURACY SCORE\", accuracy_score(y_test, y_pred_bclf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, these seem to keep getting better, perhaps a random forest will rule them all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimators:  5 5x CV score:  0.708611168112\n",
      "number of estimators:  10 5x CV score:  0.737517513259\n",
      "number of estimators:  20 5x CV score:  0.73160299498\n",
      "number of estimators:  30 5x CV score:  0.717466862862\n",
      "number of estimators:  40 5x CV score:  0.714728354713\n",
      "number of estimators:  50 5x CV score:  0.711628353545\n",
      "number of estimators:  60 5x CV score:  0.703216967549\n",
      "number of estimators:  70 5x CV score:  0.706074110407\n",
      "number of estimators:  80 5x CV score:  0.708888627518\n"
     ]
    }
   ],
   "source": [
    "for n_est in [5,10,20,30,40,50,60,70,80]:\n",
    "    rfClf = RandomForestClassifier(n_estimators=n_est)\n",
    "    print 'number of estimators: ',n_est, '5x CV score: ', cross_val_score(rfClf,all_X_feats ,y\n",
    "                                                                           , cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meh, not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST ACCURACY SCORE 0.771428571429\n"
     ]
    }
   ],
   "source": [
    "rfClf_10 = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "rfClf_10.fit(X_train_features, y_train)\n",
    "ypred_RF = rfClf_10.predict(X_test_features)\n",
    "\n",
    "print \"RANDOM FOREST ACCURACY SCORE\", accuracy_score(y_test, ypred_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's see where an old school linear regression gets us on this one, using pipeline, just for kicks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0]}\n",
    "              ]\n",
    "\n",
    "pl = Pipeline([('vect', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_pl = GridSearchCV(pl, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=2,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "report = cross_val_score(gs_pl, X, y, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CVx5 report [ 0.76712329  0.8         0.74285714  0.75362319  0.75      ]\n"
     ]
    }
   ],
   "source": [
    "print \"CVx5 report\" , report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR PIPELINE ACCURACY SCORE 0.842857142857\n"
     ]
    }
   ],
   "source": [
    "gs_pl.fit(X_train, y_train)\n",
    "y_pred_GSPL = gs_pl.predict(X_test)\n",
    "print \"LR PIPELINE ACCURACY SCORE\", accuracy_score(y_test, y_pred_GSPL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALRIGHT, this all seems well and good, but we're data scientists and want to predict on data from the wild. So let's grab some 2016 movie data and get crazy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_movies_url = \"http://www.imdb.com/search/title?year=2016,2016&title_type=feature&sort=user_rating,desc\"\n",
    "good_movies_html = requests.get(good_movies_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_movies_soup = BeautifulSoup(good_movies_html.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"ribbonize\" data-caller=\"filmosearch\" data-tconst=\"tt5825058\"></div>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodm_divs = good_movies_soup.findAll(\"div\",{\"class\":\"ribbonize\"})\n",
    "goodm_divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'tt5825058'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(goodm_divs[0].text)\n",
    "goodm_divs[0][\"data-tconst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m2016_ids = []\n",
    "for div_elm in goodm_divs:\n",
    "    m2016_ids.append(div_elm['data-tconst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_2016_as_text = []\n",
    "review_2016_rating_as_int = []\n",
    "\n",
    "for tconst in m2016_ids:\n",
    "    try:\n",
    "        reviews_for_movie_i = imdb.get_title_reviews(tconst, max_results=2)\n",
    "        if reviews_for_movie_i is None:\n",
    "            continue\n",
    "        for movie in reviews_for_movie_i:\n",
    "            reviews_2016_as_text.append(movie.text)\n",
    "            review_2016_rating_as_int.append(movie.rating)\n",
    "    except ConnectionError:\n",
    "        print 'werent able to get movie', tconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_movies_url = \"http://www.imdb.com/search/title?year=2016,2016&title_type=feature&sort=user_rating,asc\"\n",
    "bad_movies_html = requests.get(bad_movies_url)\n",
    "bad_movies_soup = BeautifulSoup(bad_movies_html.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badm_divs = bad_movies_soup.findAll(\"div\",{\"class\":\"ribbonize\"})\n",
    "bm2016_ids = []\n",
    "for div_elm in badm_divs:\n",
    "    bm2016_ids.append(div_elm['data-tconst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_2016 = m2016_ids + bm2016_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_2016_as_text = []\n",
    "review_2016_rating_as_int = []\n",
    "\n",
    "for tconst in all_2016:\n",
    "    try:\n",
    "        reviews_for_movie_i = imdb.get_title_reviews(tconst, max_results=2)\n",
    "        if reviews_for_movie_i is None:\n",
    "            continue\n",
    "        for movie in reviews_for_movie_i:\n",
    "            reviews_2016_as_text.append(movie.text)\n",
    "            review_2016_rating_as_int.append(movie.rating)\n",
    "    except ConnectionError:\n",
    "        print 'werent able to get movie', tconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print len(reviews_2016_as_text)\n",
    "print len(review_2016_rating_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>This is my first IMDb review, please excuse my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>In Bangladesh movie industry are not helpful, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings                                            reviews\n",
       "0     10.0  This is my first IMDb review, please excuse my...\n",
       "1     10.0  In Bangladesh movie industry are not helpful, ..."
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016_movies = pd.DataFrame({'reviews': reviews_2016_as_text , 'ratings': review_2016_rating_as_int})\n",
    "df_2016_movies = df_2016_movies.dropna()\n",
    "df_2016_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2016 = df_2016_movies['reviews']\n",
    "y_2016 = df_2016_movies['ratings'].astype(int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make_2016_features = TfidfVectorizer(stop_words='english', strip_accents = 'ascii')\n",
    "make_2016_features.fit(X_train)\n",
    "all_X_feats = make_2016_features.transform(X_train)\n",
    "X_2016_features = make_2016_features.transform(X_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREEE ACCURACY SCORE 0.131147540984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ypred_2016_tclf = TreeClf_a.predict(X_2016_features)\n",
    "print \"DECISION TREEE ACCURACY SCORE\", accuracy_score(y_2016, ypred_2016_tclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGED TREE ACCURACY SCORE 0.0819672131148\n"
     ]
    }
   ],
   "source": [
    "y_pred_bclf3 = BAgg_clf_30.predict(X_2016_features)\n",
    "print \"BAGGED TREE ACCURACY SCORE\", accuracy_score(y_2016, y_pred_bclf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGED TREE W/ FEAT BAGGING ACCURACY SCORE 0.0819672131148\n"
     ]
    }
   ],
   "source": [
    "# BAgg_clf_50 = BaggingClassifier(base_estimator=DTree_clf,  n_estimators=50, bootstrap_features=True)\n",
    "# BAgg_clf_50.fit(X_train_features, y_train) \n",
    "y_pred_bclf5_16 = BAgg_clf_50.predict(X_2016_features)\n",
    "print \"BAGGED TREE W/ FEAT BAGGING ACCURACY SCORE\", accuracy_score(y_2016, y_pred_bclf5_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST ACCURACY SCORE 0.0983606557377\n"
     ]
    }
   ],
   "source": [
    "# rfClf_10 = RandomForestClassifier(n_estimators=10)\n",
    "# rfClf_10.fit(X_train_features, y_train)\n",
    "ypred_RF_16 = rfClf_10.predict(X_2016_features)\n",
    "\n",
    "print \"RANDOM FOREST ACCURACY SCORE\", accuracy_score(y_2016, ypred_RF_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusions: \n",
    "\n",
    "These models are drastically overfit! They would benefit from increased regularization so that they generalize better. It's also worth considering that a classification technique would be better with fewer numerical targets. Instead of trying to map to values 1-10, a simpler classification scheme might map to values above 7 or under 7 and call these \"good\" or \"bad\". "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
